{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description\n",
    "\n",
    "With increasing renewable engergy generation and therefor rising fluctation of generated power, intelligent electricity grids are necessary for the balance between demand and the generation. The amount of feed-in power to the grid has to be at every time equal to the feed-out power, otherwise the grid gets unstable and can cause a black-out to a wider region. Also the sectors mobility, heating and industry are transforming there currently fossil-driven energy generators to electricity-based technologies, which will, despite of the conduction of energry efficiancy measures, lead to higher power demands in future.\n",
    "\n",
    "This project uses a power plant register and measured time series of generation and consumption of Germany to provide a solid database for further electricity demand forecasts and simulations concerning different scenarios of the energetic transformation of our economies.\n",
    "\n",
    "In this sample, the following sources are referenced:\n",
    "\n",
    "1. Markstammdatenregister\n",
    "Datenlizenz Deutschland – Namensnennung – Version 2.0 // http://www.govdata.de/dl-de/by-2-0\n",
    "https://www.marktstammdatenregister.de/MaStR/Datendownload\n",
    "\n",
    "2. Bundesnetzagentur | SMARD.de\n",
    "https://www.smard.de/home/downloadcenter/download-marktdaten/\n",
    "\n",
    "3. GeoJSON data Germany\n",
    "https://github.com/yetzt/postleitzahlen/blob/main/data/postleitzahlen.geojson"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "Download current version of the data:\n",
    "\n",
    "1. MaStR\n",
    "\thttps://www.marktstammdatenregister.de/MaStR/Datendownload\n",
    "\tDownload in section \"Gesamtdatenauszug vom Vortag\" the big ZIP-file and unpack it in a folder named \"Gesamtdatenauszug_MaStR\".\n",
    "\n",
    "\n",
    "2. SMARD.de\n",
    "\thttps://www.smard.de/home/downloadcenter/download-marktdaten/\n",
    "\tYou need to download for each combination of \"Oberkategorie\" and \"Datenkategorie\" a csv-file. This code sample works for the following time series:\n",
    "    \n",
    "\tOberkategorie: Stromerzeugung // Datenkategorie: Realisierte Erzeugung\n",
    "    \n",
    "\tOberkategorie: Stromerzeugung // Datenkategorie: Prognostizierte Erzeugung\n",
    "    \n",
    "\tOberkategorie: Stromerverbrauch // Datenkategorie: Realisierter Stromverbrauch\n",
    "    \n",
    "\tOberkategorie: Stromerverbrauch // Datenkategorie: Prognostizierter Stromverbrauch\n",
    "    \n",
    "\tOberkategorie: Stromerzeugung // Datenkategorie: Installierte Erzeugerleistung\n",
    "\n",
    "\t\n",
    "\tChoose as \"Land/Regelzone\" the element \"Land: Deutschland\".\n",
    "\t\n",
    "\tSelect the time period you want to analyse. If you want to download multiple years, best download for each year a csv.\n",
    "\t\n",
    "\tChoose \"Auflösung wählen: Viertelstunde\" and \"Dateiformat: CSV\". For the last combination \"Oberkategorie: Stromerzeugung // Datenkategorie: Installierte Erzeugerleistung\" choose \"Auflösung: Tag\".\n",
    "\n",
    "\tSave these files in a folder named \"smard_historical_data\".\n",
    "\n",
    "\tCopy the two folder \"Gesamtdatenexport\" and \"Gesamtdatenauszug_MaStR\" in a folder named \"01_raw_data\".\n",
    "\n",
    "3. GeoJSON data Germany\n",
    "\thttps://github.com/yetzt/postleitzahlen/blob/main/data/postleitzahlen.geojson\n",
    "\n",
    "\t\"name\": \"postleitzahlen-de\", \"version\": \"1.0.2\", \"description\": \"german postcode areas 2023\", \"license\": \"ODbL-1.0\",\n",
    "\t\"contributors\": [{\n",
    "\t\t\t\"name\": \"yetzt\",\n",
    "\t\t\t\"url\": \"https://yetzt.me\"\n",
    "\t\t},{\n",
    "\t\t\t\"name\": \"OpenStreetMap contributors\",\n",
    "\t\t\t\"url\": \"https://www.openstreetmap.org/\"\n",
    "\t\t}],\n",
    "\t\"repository\": {\n",
    "\t\t\"type\": \"git\",\n",
    "\t\t\"url\": \"https://github.com/yetzt/postleitzahlen.git\"}\n",
    "\n",
    "4. folder structure\n",
    "\tCreate somewhere on your computer a folder and create two folder in it (on the same level): \"code_samples\" and \"code_samples_data\"\n",
    "\n",
    "\tCreate in each of these two folders an empty folder named \"01_smard_grids\"\n",
    "\n",
    "\tCopy the content of this repository in code_samples/01_smard_grids\n",
    "\n",
    "\tCopy the folder \"01_raw_data\" in code_samples_data/01_smard_grids\n",
    "\n",
    "\tSave postleitzahlen.geojson in the folder ..\\\\code_samples_data/01_smard_grids\\\\01_raw_data\\\\postcodes_geodata_Germany'\n",
    "\n",
    "5. You will need to change some pathes in the code:\n",
    "\n",
    "\tcommon_namespace_SG.py : line 54 and 56\n",
    "\n",
    "\tapp.py : line 5 (depending on your enviroment)\n",
    "\n",
    "5. Continue with this notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from python file\n",
    "import sys\n",
    "#sys.path.append(\"..\")\n",
    "#path_to_modules = 'D:\\\\Coding\\\\code_samples\\\\smard_grids'\n",
    "#sys.path.append(path_to_modules)\n",
    "import common_namespace_SG as cn\n",
    "import common_functions_SG as cf\n",
    "\n",
    "\n",
    "# import other packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import exists\n",
    "import json\n",
    "import pyproj\n",
    "import time\n",
    "#from datetime import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "#!pip install geopy\n",
    "from geopy import distance\n",
    "import math\n",
    "#!pip install geopandas\n",
    "import geopandas\n",
    "\n",
    "#!pip install geojson'\n",
    "import geojson\n",
    "#!pip install geopandas\n",
    "import geopandas\n",
    "\n",
    "# Import Meteostat library and dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install meteostat\n",
    "from meteostat import Point, Daily, Hourly\n",
    "\n",
    "\n",
    "# Create names space\n",
    "\n",
    "path_dict = cn.create_path_names_dict()                        # Create pathnames\n",
    "file_names_dict = cn.create_file_names_dict()                  # Create filenames\n",
    "model_dict = cn.create_model_dict()                            # Create model parameters\n",
    "cf.check_folder_struture(path_dict)                            # check that all necessary folders exist, if not, create empty folders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durations:\n",
    "\n",
    "timeseries SMARD.de : ~ 1 min\n",
    "\n",
    "complete extraction MaStR : ~ 8 h\n",
    "\n",
    "additional joining operator information to MaStR extraction : ~ 8 h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time series of SMARD.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- extract data from MaStR - smard.de ---\n",
    "cf.preprocess_smard_historical_data()                   # ~ 1 min processing time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to your terminal, change directory and execute \"python app.py\" to browse raw data with dash plotly. Otherwise you can load app.py to VSCode Editor and press \"Run Python File\" top right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manual inspection in yupiter\n",
    "df = cf.load_historical_gen_and_con_in_one_df()\n",
    "input_year = ''\n",
    "\n",
    "# select feature\n",
    "## df.columns = {0: 'Biomasse [MW]', 1: 'Wasserkraft [MW]', 2: 'Wind Offshore [MW]', 3: Wind Onshore [MW], 4: Photovoltaik [MW], \n",
    "##               5: 'Sonstige Erneuerbare [MW]', 6: 'Kernenergie [MW]', 7: 'Braunkohle [MW]',8: 'Steinkohle [MW]', 9: 'Erdgas [MW]', \n",
    "##               10: 'Pumpspeicher [MW]', 11: 'Sonstige Konventionelle [MW]'}\n",
    "input_value = df.columns[0]\n",
    "\n",
    "# create plots\n",
    "fig_1 = cf.plot_single_raw_time_serie(df, df.columns.get_loc(input_value))\n",
    "energy_amount_per_year, energy_amount_per_year_per_year_and_month, energy_amount_per_year_per_day, energy_amount_per_week = cf.aggregate_energy_amounts_as_df(df, input_value)\n",
    "fig_2 = cf.plot_aggregates_energy_amounts_per_year(energy_amount_per_year)\n",
    "fig_3 = cf.plot_aggregates_energy_amounts_per_year_and_month(energy_amount_per_year_per_year_and_month)\n",
    "fig_4 = cf.plot_aggregates_energy_amounts_per_day(energy_amount_per_year_per_day)\n",
    "fig_5 = cf.plot_aggregates_energy_amounts_per_week(energy_amount_per_week)\n",
    "heatmap_df_h_wd, input_year = cf.create_df_for_yearly_heatmap_hour_weekday(df, input_value, input_year)\n",
    "fig_6 = cf.plot_timeseries_heatmap_hour_weekday(heatmap_df_h_wd, input_value, input_year)\n",
    "heatmap_df_h_m, input_year = cf.create_df_for_yearly_heatmap_hour_month(df, input_value, input_year)\n",
    "fig_7 = cf.plot_timeseries_heatmap_hours_month(heatmap_df_h_m, input_value, input_year)\n",
    "fig_8, df_ldc_multiple = cf.plot_annual_load_duration_curve_multiple_years(df, input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1\n",
    "#fig_2\n",
    "#fig_3\n",
    "#fig_4\n",
    "#fig_5\n",
    "#fig_6\n",
    "#fig_7\n",
    "#fig_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check installed power\n",
    "df_installed_power = cf.load_installed_power_as_df()\n",
    "\n",
    "# select feature\n",
    "check_prefix = {0: 'Biomasse_[MW]', 1: 'Wasserkraft_[MW]', 2: 'Wind_Offshore_[MW]', 3: 'Wind_Onshore_[MW]', 4: 'Photovoltaik_[MW]', \n",
    "               5: 'Sonstige_Erneuerbare_[MW]', 6: 'Kernenergie_[MW]', 7: 'Braunkohle_[MW]',8: 'Steinkohle_[MW]', 9: 'Erdgas_[MW]', \n",
    "               10: 'Pumpspeicher_[MW]', 11: 'Sonstige_Konventionelle_[MW]'}\n",
    "input_value = check_prefix[3]\n",
    "\n",
    "fig_9 = cf.plot_single_installed_power(df_installed_power, input_value)\n",
    "fig_9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## power plant register from MaStR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extration of data from MaStR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extraction of the all XML-files takes round about 8 hours. Please consider the following processing times for each generation technology and start with a small batch.\n",
    "\n",
    "['prefix_solar_unity'] : '7 h',\n",
    "\n",
    "['prefix_storage_unity'] : '60 mins',\n",
    "\n",
    "['prefix_grid_Marktakteure_unity'] : '45 mins'\n",
    "\n",
    "['prefix_combustion_unity'] : '14 mins',\n",
    "\n",
    "['prefix_wind_unity'] : '3 mins',\n",
    "\n",
    "['prefix_biomass_unity'] : '1 mins',\n",
    "\n",
    "The extractions of the other categories are processed quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- extract information from xml files of MaStR\n",
    "\n",
    "## -------- call multiple prefix_data_type -------- ##\n",
    "# the prefix is the class of xml-files of MaStR-Export\n",
    "process_these_prefix_data_types = {\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_solar_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_wind_unity']),\n",
    "\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_biomass_unity']),\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_ee_other_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_nuclear_generator_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_power_consumer_unity']),\n",
    "\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_combustion_unity']),\n",
    "\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_water_generator_unity']),\n",
    "\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_storage_unity']),\n",
    "\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_gas_generator_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_gas_storage_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_gas_consumer_unity']),\n",
    "\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_grid_Marktakteure_unity']),\n",
    "\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_grid_balancing_area']),\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_grid_single_grid_unity']),\n",
    "\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_grid_roles_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_grid_value_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_grid_category_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_grid_unittypes_unity']),\n",
    "                                    }\n",
    "\n",
    "#### --- extract data from MaStR ---\n",
    "for prefix_data_type in process_these_prefix_data_types:\n",
    "    #cf.extract_data_from_MaStR_from_xml_to_csv(prefix_data_type)            # one fct for all kinds of unity types\n",
    "    #dataframe_unity = cf.extract_data_from_MaStR_from_xml_to_csv(prefix_data_type)            # one fct for all kinds of unity types with fct export\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionaly you can operator information to the units. The additional process duration times per prefix_data_type is comparable to these of the XML-Exports. For a first data inspection you don't need these informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_operator_information_of_these_prefix_data_types = {\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_solar_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_wind_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_biomass_unity']),\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_ee_other_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_nuclear_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_power_consumer_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_combustion_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_water_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_consumer_unity']),\n",
    "                                    }\n",
    "\n",
    "# hint: prefix_solar_unity and prefix_storage_unity to be validated\n",
    "for prefix_data_type in add_operator_information_of_these_prefix_data_types:\n",
    "    cf.add_operator_information(prefix_data_type)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check preprocessed files MaStR\n",
    "list_files_operator, list_files_without_operator = cf.check_complete_MaStR_xml_extractions()\n",
    "print(f'units with operator infos : {list_files_operator}')\n",
    "print(f'units without operator infos : {list_files_without_operator}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore MaStR data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check extractions\n",
    "prefix_data_type = file_names_dict['filenames_raw']['prefix_solar_unity']\n",
    "\n",
    "df_MaStR = cf.load_unity_extractions_from_MaStR(prefix_data_type)\n",
    "#df_MaStR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration with geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load geodata information of Germany\n",
    "gdf, gdff, gdf_transformed = cf.load_geojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select energy vector, perform aggregation and merge with geodataframe\n",
    "plot_these_prefix_data_types = {\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_solar_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_wind_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_biomass_unity']),\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_ee_other_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_nuclear_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_power_consumer_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_combustion_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_water_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_consumer_unity']),\n",
    "                                    }\n",
    "\n",
    "# Select energy vector\n",
    "prefix_data_type = list(plot_these_prefix_data_types)[0]\n",
    "df_MaStR = cf.load_unity_extractions_from_MaStR(prefix_data_type)\n",
    "\n",
    "# Select aggregation features\n",
    "#aggregation_features = ['Bruttoleistung', 'Nettonennleistung']\n",
    "class_features = 0\n",
    "aggregation_feature = model_dict['aggregation_feature_per_postcode_classes_for_installed_power'][prefix_data_type][class_features]\n",
    "\n",
    "# group feature and merge df with geodf\n",
    "df_MaStR_postcode_aggregates = cf.aggregate_MaStR_extraction_per_postcode(df_MaStR, prefix_data_type, aggregation_feature)\n",
    "merged_data = pd.merge(gdf, df_MaStR_postcode_aggregates, left_on='postcode', right_on='Postleitzahl', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static output:\n",
    "vmax_input = 6000\n",
    "cmap_input = prefix_data_type\n",
    "print(prefix_data_type)\n",
    "#merged_data.plot(column=aggregation_feature, legend='True', vmax=vmax_input)\n",
    "merged_data.plot(column=aggregation_feature, legend='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive map\n",
    "print(prefix_data_type)\n",
    "fig_2 = merged_data.explore(aggregation_feature, legend='True')\n",
    "fig_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore with plotly (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load geodata information of Germany\n",
    "gdf, gdff, gdf_transformed = cf.load_geojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select energy vector, perform aggregation and merge with geodataframe\n",
    "plot_these_prefix_data_types = {\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_solar_unity']),\n",
    "                                    str(file_names_dict['filenames_raw']['prefix_wind_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_biomass_unity']),\n",
    "                                    ##str(file_names_dict['filenames_raw']['prefix_ee_other_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_nuclear_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_power_consumer_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_combustion_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_water_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_generator_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_storage_unity']),\n",
    "                                    #str(file_names_dict['filenames_raw']['prefix_gas_consumer_unity']),\n",
    "                                    }\n",
    "\n",
    "# Select energy vector\n",
    "prefix_data_type = list(plot_these_prefix_data_types)[0]\n",
    "df_MaStR = cf.load_unity_extractions_from_MaStR(prefix_data_type)\n",
    "\n",
    "# Select aggregation features\n",
    "#aggregation_features = ['Bruttoleistung', 'Nettonennleistung']\n",
    "class_features = 0\n",
    "aggregation_feature = model_dict['aggregation_feature_per_postcode_classes_for_installed_power'][prefix_data_type][class_features]\n",
    "\n",
    "# group feature and merge df with geodf\n",
    "df_MaStR_postcode_aggregates = cf.aggregate_MaStR_extraction_per_postcode(df_MaStR, prefix_data_type, aggregation_feature)\n",
    "merged_data = pd.merge(gdf, df_MaStR_postcode_aggregates, left_on='postcode', right_on='Postleitzahl', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_dict['postcodes_geodata'])\n",
    "filename = 'postleitzahlen.geojson'\n",
    "gdf = geopandas.read_file(filename)\n",
    "gdf.to_file('main_map.geojson', driver='GeoJSON')\n",
    "#gdf_transformed.to_file('main_map.geojson', driver='GeoJSON')\n",
    "with open ('main_map.geojson', 'r') as infile:\n",
    "    map_json = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = px.choropleth_mapbox(df_MaStR_postcode_aggregates, geojson=map_json,\n",
    "                             locations='Postleitzahl', featureidkey='properties.postcode',\n",
    "                             color=aggregation_feature,\n",
    "                             )\n",
    "fig_1.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SG2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
